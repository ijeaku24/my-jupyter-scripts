{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3c10f0-9497-46d7-a4f3-73f7b298b856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0846ce-2650-4e11-ade6-ce56a0b5b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning longitude and latitude from pee_maj (.gpkg) to csv files (*_final.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0b50306-9e26-42eb-abdb-950bc369ceac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "  Downloading geopandas-1.1.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.24 in /opt/anaconda3/lib/python3.13/site-packages (from geopandas) (2.1.3)\n",
      "Collecting pyogrio>=0.7.2 (from geopandas)\n",
      "  Downloading pyogrio-0.11.1-cp313-cp313-macosx_12_0_arm64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.13/site-packages (from geopandas) (24.2)\n",
      "Collecting pyproj>=3.5.0 (from geopandas)\n",
      "  Downloading pyproj-3.7.2-cp313-cp313-macosx_14_0_arm64.whl.metadata (31 kB)\n",
      "Collecting shapely>=2.0.0 (from geopandas)\n",
      "  Downloading shapely-2.1.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.13/site-packages (from pyogrio>=0.7.2->geopandas) (2025.8.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading geopandas-1.1.1-py3-none-any.whl (338 kB)\n",
      "Downloading pyogrio-0.11.1-cp313-cp313-macosx_12_0_arm64.whl (19.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Downloading pyproj-3.7.2-cp313-cp313-macosx_14_0_arm64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Downloading shapely-2.1.1-cp313-cp313-macosx_11_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Installing collected packages: shapely, pyproj, pyogrio, geopandas\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [geopandas]/4\u001b[0m [geopandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed geopandas-1.1.1 pyogrio-0.11.1 pyproj-3.7.2 shapely-2.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install geopandas pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b426777-86c1-477c-95d3-c68ff84485ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fiona\n",
      "  Downloading fiona-1.10.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (56 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from fiona) (24.3.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.13/site-packages (from fiona) (2025.8.3)\n",
      "Requirement already satisfied: click~=8.0 in /opt/anaconda3/lib/python3.13/site-packages (from fiona) (8.1.8)\n",
      "Collecting click-plugins>=1.0 (from fiona)\n",
      "  Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting cligj>=0.5 (from fiona)\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Downloading fiona-1.10.1-cp313-cp313-macosx_11_0_arm64.whl (14.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl (11 kB)\n",
      "Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Installing collected packages: cligj, click-plugins, fiona\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [fiona]\n",
      "Successfully installed click-plugins-1.1.1.2 cligj-0.7.2 fiona-1.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b765ab-31ae-48d2-9b7e-f7df477c413b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d8d268f-2482-4521-ae45-f162b3bf75b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available layers: ['carte_eco_maj_prov__pee_maj']\n",
      "✅ Saved: extracted_data_part_10_final_with_coords.csv\n",
      "✅ Saved: extracted_data_part_1_final_with_coords.csv\n",
      "✅ Saved: extracted_data_part_2_final_with_coords.csv\n",
      "✅ Saved: extracted_data_part_3_final_with_coords.csv\n",
      "✅ Saved: extracted_data_part_4_final_with_coords.csv\n",
      "✅ Saved: extracted_data_part_5_final_with_coords.csv\n",
      "✅ Saved: extracted_data_part_6_final_with_coords.csv\n",
      "✅ Saved: extracted_data_part_7_final_with_coords.csv\n",
      "✅ Saved: extracted_data_part_8_final_with_coords.csv\n",
      "✅ Saved: extracted_data_part_9_final_with_coords.csv\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import fiona  # Added this import to fix the NameError\n",
    "from pathlib import Path\n",
    "\n",
    "# === Step 1: File paths ===\n",
    "csv_dir = Path(\"/Volumes/My Passport/age-dbh_jesus/RF_my_study_area/dendro_arbres_date-sond_age/SOC_siigsol/SOC_mineral_layer_100m/SOC_database_from_Frédérik/New folder/\")\n",
    "gpkg_path = Path(\"/Users/adimi/Desktop/CARTE_ECO_MAJ_PROV-pee_maj/pee_maj.gpkg\")\n",
    "\n",
    "# === Step 2: Load the GPKG ===\n",
    "# Check available layers first (optional)\n",
    "layers = fiona.listlayers(gpkg_path)\n",
    "print(\"Available layers:\", layers)\n",
    "\n",
    "# Read the default or desired layer\n",
    "gdf = gpd.read_file(gpkg_path, layer=layers[0])\n",
    "coords_df = gdf[[\"geoc_maj\", \"geocode\", \"latitude\", \"longitude\"]].copy()\n",
    "\n",
    "# === Step 3: Merge coordinates into each CSV ===\n",
    "csv_files = sorted(csv_dir.glob(\"extracted_data_part_*_final.csv\"))\n",
    "\n",
    "for csv_path in csv_files:\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    merged = df.merge(coords_df, on=[\"geoc_maj\", \"geocode\"], how=\"left\")\n",
    "\n",
    "    out_path = csv_path.with_name(csv_path.stem + \"_with_coords.csv\")\n",
    "    merged.to_csv(out_path, index=False)\n",
    "\n",
    "    print(f\"✅ Saved: {out_path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62686f49-e4bd-43b6-be8a-719971a025e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84243258-aca3-476d-9bf8-1b415f0ca697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available layers: ['joined_layer']\n",
      "✅ Saved: extracted_data_part_10_final_with_coords_with_attrs.csv\n",
      "✅ Saved: extracted_data_part_1_final_with_coords_with_attrs.csv\n",
      "✅ Saved: extracted_data_part_2_final_with_coords_with_attrs.csv\n",
      "✅ Saved: extracted_data_part_3_final_with_coords_with_attrs.csv\n",
      "✅ Saved: extracted_data_part_4_final_with_coords_with_attrs.csv\n",
      "✅ Saved: extracted_data_part_5_final_with_coords_with_attrs.csv\n",
      "✅ Saved: extracted_data_part_6_final_with_coords_with_attrs.csv\n",
      "✅ Saved: extracted_data_part_7_final_with_coords_with_attrs.csv\n",
      "✅ Saved: extracted_data_part_8_final_with_coords_with_attrs.csv\n",
      "✅ Saved: extracted_data_part_9_final_with_coords_with_attrs.csv\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import fiona  # Added this import to fix the NameError\n",
    "from pathlib import Path\n",
    "\n",
    "# === Step 1: File paths ===\n",
    "csv_dir = Path(\"/Volumes/My Passport/age-dbh_jesus/RF_my_study_area/dendro_arbres_date-sond_age/SOC_siigsol/SOC_mineral_layer_100m/SOC_database_from_Frédérik/New folder/\")\n",
    "gpkg_path = Path(\"/Users/adimi/PyCharm_SOC/SOC_classifier/new_data/pee_maj_with_additionals.gpkg\")  # <-- update file path\n",
    "\n",
    "# === Step 2: Load the GPKG and select needed columns ===\n",
    "# Check available layers first (optional)\n",
    "layers = fiona.listlayers(gpkg_path)\n",
    "print(\"Available layers:\", layers)\n",
    "\n",
    "# Read the default or desired layer\n",
    "gdf = gpd.read_file(gpkg_path, layer=layers[0])\n",
    "attrs_df = gdf[[\"geoc_maj\", \"geocode\", \n",
    "    \"altitude\", \"pc_pent\", \"haut_domi\", \"couv_arbo1\", \"drai_synth\"]].copy()\n",
    "\n",
    "# === Step 3: Merge coordinates into each CSV ===\n",
    "csv_files = sorted(csv_dir.glob(\"extracted_data_part_*_final_with_coords.csv\"))\n",
    "\n",
    "for csv_path in csv_files:\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    merged = df.merge(attrs_df, on=[\"geoc_maj\", \"geocode\"], how=\"left\")\n",
    "\n",
    "    out_path = csv_path.with_name(csv_path.stem + \"_with_attrs.csv\")\n",
    "    merged.to_csv(out_path, index=False)\n",
    "\n",
    "    print(f\"✅ Saved: {out_path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49e214d-bb33-4de0-924a-abb78634dac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0453bf11-f01e-41a8-bc38-e77d0a06a486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 CSV files to merge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z1/kq7wtwps42nbrhvmr74j6r_40000gn/T/ipykernel_1254/3954014920.py:17: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n",
      "/var/folders/z1/kq7wtwps42nbrhvmr74j6r_40000gn/T/ipykernel_1254/3954014920.py:17: DtypeWarning: Columns (25,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n",
      "/var/folders/z1/kq7wtwps42nbrhvmr74j6r_40000gn/T/ipykernel_1254/3954014920.py:17: DtypeWarning: Columns (25,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n",
      "/var/folders/z1/kq7wtwps42nbrhvmr74j6r_40000gn/T/ipykernel_1254/3954014920.py:17: DtypeWarning: Columns (25,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n",
      "/var/folders/z1/kq7wtwps42nbrhvmr74j6r_40000gn/T/ipykernel_1254/3954014920.py:17: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n",
      "/var/folders/z1/kq7wtwps42nbrhvmr74j6r_40000gn/T/ipykernel_1254/3954014920.py:17: DtypeWarning: Columns (25,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n",
      "/var/folders/z1/kq7wtwps42nbrhvmr74j6r_40000gn/T/ipykernel_1254/3954014920.py:17: DtypeWarning: Columns (25,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n",
      "/var/folders/z1/kq7wtwps42nbrhvmr74j6r_40000gn/T/ipykernel_1254/3954014920.py:17: DtypeWarning: Columns (25,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged GPKG saved as: /Volumes/My Passport/age-dbh_jesus/RF_my_study_area/dendro_arbres_date-sond_age/SOC_siigsol/SOC_mineral_layer_100m/SOC_database_from_Frédérik/New folder/merged_extracted_data_final_with_coords_with_attrs.gpkg\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from pathlib import Path\n",
    "\n",
    "# === Step 1: Folder path ===\n",
    "csv_dir = Path(\"/Volumes/My Passport/age-dbh_jesus/RF_my_study_area/dendro_arbres_date-sond_age/SOC_siigsol/SOC_mineral_layer_100m/SOC_database_from_Frédérik/New folder/\")\n",
    "\n",
    "# === Step 2: Find all matching CSV files ===\n",
    "csv_files = sorted(csv_dir.glob(\"extracted_data_part_*_final_with_coords_with_attrs.csv\"))\n",
    "print(f\"Found {len(csv_files)} CSV files to merge.\")\n",
    "\n",
    "# === Step 3: Read CSVs and convert to GeoDataFrames ===\n",
    "gdfs = []\n",
    "\n",
    "for csv_path in csv_files:\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Create geometry from longitude / latitude\n",
    "    # NOTE: These are assumed to already be in EPSG:32198\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df,\n",
    "        geometry=[Point(xy) for xy in zip(df[\"longitude\"], df[\"latitude\"])],\n",
    "        crs=\"EPSG:32198\"\n",
    "    )\n",
    "    gdfs.append(gdf)\n",
    "\n",
    "# === Step 4: Merge all GeoDataFrames ===\n",
    "merged_gdf = pd.concat(gdfs, ignore_index=True)\n",
    "merged_gdf = gpd.GeoDataFrame(merged_gdf, geometry=\"geometry\", crs=\"EPSG:32198\")\n",
    "\n",
    "# === Step 5: Save as GeoPackage ===\n",
    "out_path = csv_dir / \"merged_extracted_data_final_with_coords_with_attrs.gpkg\"\n",
    "merged_gdf.to_file(out_path, driver=\"GPKG\")\n",
    "\n",
    "print(f\"✅ Merged GPKG saved as: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2664351b-83f6-43ed-8f6e-803eefa354c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes (columns) in the GPKG:\n",
      "['geoc_maj', 'geocode', 'origine', 'perturb', 'type_couv', 'cl_dens', 'cl_haut', 'cl_age', 'cl_pent', 'dep_sur', 'cl_drai', 'type_eco', 'superficie', 'dep_sur_simp', 'epais_mine', 'type_eco3', 'veg_pot', 'reg_eco', 'ind', 'latitude', 'longitude', 'altitude', 'pc_pent', 'haut_domi', 'couv_arbo1', 'drai_synth', 'geometry']\n",
      "\n",
      "CRS:\n",
      "EPSG:32198\n",
      "\n",
      "Sample rows:\n",
      "               geoc_maj               geocode origine perturb type_couv  \\\n",
      "0  -579837,53+190458,63  -579837,53+190458,63      FR    None         F   \n",
      "1  -578157,19+188819,69  -578157,19+188819,69      FR    None         F   \n",
      "2  -578549,60+189556,71  -578549,60+189556,71      FR    None         F   \n",
      "3  -580083,95+190149,47  -580083,95+190149,47      FR    None         F   \n",
      "4  -581440,49+194924,57  -581440,49+194924,57      FR    None         F   \n",
      "\n",
      "  cl_dens  cl_haut cl_age cl_pent dep_sur  ...  reg_eco     ind  \\\n",
      "0       C      5.0     10       B      5S  ...       2c  FE1_2c   \n",
      "1       C      5.0     10       B      5A  ...       2c  RB1_2c   \n",
      "2       C      5.0     10       A      5A  ...       2c  RB1_2c   \n",
      "3       B      5.0     10       B      5A  ...       2c  MJ1_2c   \n",
      "4       B      5.0     10       A      5A  ...       2c  MJ1_2c   \n",
      "\n",
      "        latitude      longitude  altitude  pc_pent haut_domi couv_arbo1  \\\n",
      "0  190444.073749 -579834.207963       NaN      NaN       NaN       None   \n",
      "1  188794.426716 -578120.357544       NaN      NaN       NaN       None   \n",
      "2  189390.773073 -578452.335778       NaN      NaN       NaN       None   \n",
      "3  190149.469013 -580083.949269       NaN      NaN       NaN       None   \n",
      "4  194924.571097 -581440.487283       NaN      NaN       NaN       None   \n",
      "\n",
      "  drai_synth                        geometry  \n",
      "0       None  POINT (-579834.208 190444.074)  \n",
      "1       None  POINT (-578120.358 188794.427)  \n",
      "2       None  POINT (-578452.336 189390.773)  \n",
      "3       None  POINT (-580083.949 190149.469)  \n",
      "4       None  POINT (-581440.487 194924.571)  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Path to your merged GPKG file\n",
    "gpkg_path = '/Volumes/My Passport/age-dbh_jesus/RF_my_study_area/dendro_arbres_date-sond_age/SOC_siigsol/SOC_mineral_layer_100m/SOC_database_from_Frédérik/New folder/merged_extracted_data_final_with_coords_with_attrs.gpkg'\n",
    "\n",
    "# Load the GPKG\n",
    "gdf = gpd.read_file(gpkg_path)\n",
    "\n",
    "# Show all column names (attributes)\n",
    "print(\"Attributes (columns) in the GPKG:\")\n",
    "print(gdf.columns.tolist())\n",
    "\n",
    "# Show the CRS (should be EPSG:32198)\n",
    "print(\"\\nCRS:\")\n",
    "print(gdf.crs)\n",
    "\n",
    "# Show first few rows to preview data\n",
    "print(\"\\nSample rows:\")\n",
    "print(gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fca773-8b00-4d96-87a3-e8a2979d2370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7276af37-11fe-480c-8189-69202c951122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOC prediction using the ECO_FOR database variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a7c929-9051-48f1-80ab-93d199c3d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import shapely.wkt\n",
    "import pandas as pd\n",
    "\n",
    "# === File paths ===\n",
    "gpkg_path = Path(\"/Users/adimi/PyCharm_SOC/SOC_classifier/new_data/merged_extracted_data_final_with_coords_with_attrs.gpkg\")\n",
    "models_dir = Path(\"/Users/adimi/PyCharm_SOC/SOC_classifier/plots2\")\n",
    "output_dir = models_dir  # save outputs in the same folder as the RF models\n",
    "\n",
    "# === Column mapping ===\n",
    "column_mapping = {\n",
    "    \"epais_mine\": \"thickness_cm\",\n",
    "    \"veg_pot\": \"VEG_POT\",\n",
    "    \"type_couv\": \"type_couvc\",\n",
    "    \"dep_sur_simp\": \"dep_sur\"\n",
    "}\n",
    "\n",
    "# === RF models paths ===\n",
    "model_files = {\n",
    "    \"SOC_mineral_with_thickness\": models_dir / \"RF_SOC_mineral_with_thickness.pkl\",\n",
    "    \"SOC_mineral_without_thickness\": models_dir / \"RF_SOC_mineral_without_thickness.pkl\",\n",
    "    \"SOC_organic_with_thickness\": models_dir / \"RF_SOC_organic_with_thickness.pkl\",\n",
    "    \"SOC_organic_without_thickness\": models_dir / \"RF_SOC_organic_without_thickness.pkl\",\n",
    "    \"TotalSOC_with_thickness\": models_dir / \"RF_TotalSOC_with_thickness.pkl\",\n",
    "    \"TotalSOC_without_thickness\": models_dir / \"RF_TotalSOC_without_thickness.pkl\",\n",
    "}\n",
    "\n",
    "# === Load models ===\n",
    "models = {name: joblib.load(path) for name, path in model_files.items()}\n",
    "\n",
    "# === Prediction function ===\n",
    "def predict_gdf(gdf_chunk, model):\n",
    "    # Rename columns to match model features\n",
    "    gdf_chunk = gdf_chunk.rename(columns=column_mapping)\n",
    "    \n",
    "    feature_names = model.feature_names_in_\n",
    "    missing_features = [f for f in feature_names if f not in gdf_chunk.columns]\n",
    "    if missing_features:\n",
    "        raise ValueError(f\"Missing features: {missing_features}\")\n",
    "    \n",
    "    X = gdf_chunk[feature_names]\n",
    "    gdf_chunk[\"prediction\"] = model.predict(X)\n",
    "    \n",
    "    return gdf_chunk\n",
    "\n",
    "# === Read original GPKG and convert geometry to WKT for chunking ===\n",
    "gdf = gpd.read_file(gpkg_path)\n",
    "gdf[\"geometry_wkt\"] = gdf.geometry.apply(lambda x: x.wkt)\n",
    "gdf.drop(columns=\"geometry\", inplace=True)\n",
    "\n",
    "chunk_size = 500_000  # adjust depending on RAM\n",
    "\n",
    "# === Process each model separately ===\n",
    "for model_name, model in models.items():\n",
    "    first_chunk = True\n",
    "    output_file = output_dir / f\"{model_name}_predictions.gpkg\"\n",
    "    \n",
    "    for i, df_chunk in enumerate(pd.read_csv(gdf.to_csv(index=False), chunksize=chunk_size)):\n",
    "        gdf_chunk = gpd.GeoDataFrame(df_chunk, geometry=df_chunk[\"geometry_wkt\"].apply(lambda x: shapely.wkt.loads(x)), crs=gdf.crs)\n",
    "        gdf_chunk = predict_gdf(gdf_chunk, model)\n",
    "        \n",
    "        # Drop WKT column before saving\n",
    "        gdf_chunk.drop(columns=\"geometry_wkt\", inplace=True)\n",
    "        \n",
    "        # Save to GPKG\n",
    "        if first_chunk:\n",
    "            gdf_chunk.to_file(output_file, driver=\"GPKG\")\n",
    "            first_chunk = False\n",
    "        else:\n",
    "            gdf_chunk.to_file(output_file, driver=\"GPKG\", mode=\"a\")\n",
    "        \n",
    "        print(f\"{model_name}: processed chunk {i+1}\")\n",
    "    \n",
    "    print(f\"{model_name} predictions saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322b2e33-0bcf-4cb0-8ceb-b946712b9880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
